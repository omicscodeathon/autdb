{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c11034b-77b3-4953-8fcc-4247d59863e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --data-root DATA_ROOT --meta META --out OUT [--propagate-blocks]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data-root, --meta, --out\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Compute Engagnition movement_intensity for ACC with a progress bar.\n",
    "- RAW: median SVM (read if present; else compute from X/Y/Z)\n",
    "- Z:   robust z with cascade: (pid, condition) -> condition -> global\n",
    "- BIN: 1 if z >= 0 else 0\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- small helpers ----------\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return str(s).strip().lower().replace(\" \", \"\").replace(\"_\", \"\")\n",
    "\n",
    "def find_col(cols, predicate):\n",
    "    for c in cols:\n",
    "        if predicate(norm(c)):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def read_acc_csv(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read ACC CSV robustly (engine='python' helps with odd separators).\"\"\"\n",
    "    return pd.read_csv(csv_path, engine=\"python\")\n",
    "\n",
    "def get_svm_from_frame(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Return a Series with SVM per-row. If SVM present -> use it; else compute from XYZ.\"\"\"\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    # Try ready SVM-like column\n",
    "    svm_col = find_col(cols, lambda n: \"svm\" in n or \"vectormagnitude\" in n or n.endswith(\"magnitude\"))\n",
    "    if svm_col:\n",
    "        return pd.to_numeric(df[svm_col], errors=\"coerce\")\n",
    "\n",
    "    # Else look for XYZ\n",
    "    x_col = find_col(cols, lambda n: n in (\"x\",\"accx\") or n.endswith(\"accx\"))\n",
    "    y_col = find_col(cols, lambda n: n in (\"y\",\"accy\") or n.endswith(\"accy\"))\n",
    "    z_col = find_col(cols, lambda n: n in (\"z\",\"accz\") or n.endswith(\"accz\"))\n",
    "\n",
    "    # Fallback: try any columns containing 'x','y','z'\n",
    "    if not x_col: x_col = find_col(cols, lambda n: n.endswith(\"x\"))\n",
    "    if not y_col: y_col = find_col(cols, lambda n: n.endswith(\"y\"))\n",
    "    if not z_col: z_col = find_col(cols, lambda n: n.endswith(\"z\"))\n",
    "\n",
    "    if not (x_col and y_col and z_col):\n",
    "        raise ValueError(\"ACC CSV has no SVM and cannot locate X/Y/Z columns.\")\n",
    "\n",
    "    x = pd.to_numeric(df[x_col], errors=\"coerce\")\n",
    "    y = pd.to_numeric(df[y_col], errors=\"coerce\")\n",
    "    z = pd.to_numeric(df[z_col], errors=\"coerce\")\n",
    "    return np.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "def robust_center_scale(series: pd.Series):\n",
    "    \"\"\"Return (median, iqr).\"\"\"\n",
    "    v = pd.to_numeric(series, errors=\"coerce\").dropna().values\n",
    "    if len(v) == 0:\n",
    "        return np.nan, np.nan\n",
    "    med = float(np.median(v))\n",
    "    q25, q75 = np.percentile(v, 25), np.percentile(v, 75)\n",
    "    iqr = q75 - q25\n",
    "    return med, float(iqr)\n",
    "\n",
    "# ---------- main computation ----------\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data-root\", required=True, help=\"Root folder containing Engagnition and metadata.\")\n",
    "    ap.add_argument(\"--meta\", required=True, help=\"Path to metadata_master.csv (input).\")\n",
    "    ap.add_argument(\"--out\", required=True, help=\"Where to save updated metadata_master.csv.\")\n",
    "    ap.add_argument(\"--propagate-blocks\", action=\"store_true\",\n",
    "                    help=\"Copy session z/bin to block rows for same participant+condition (ACC only).\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    # Load meta\n",
    "    df = pd.read_csv(args.meta, dtype=\"object\")\n",
    "\n",
    "    # Ensure columns exist\n",
    "    for col in [\"movement_intensity_raw\", \"movement_intensity_z\", \"movement_intensity_bin\",\n",
    "                \"unit_level\", \"modality\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    # Filter: Engagnition, ACC, session-level, with path\n",
    "    mask_sess = (\n",
    "        (df.get(\"dataset\") == \"Engagnition\")\n",
    "        & ((df.get(\"modality\") == \"ACC\") | df.get(\"rel_path_acc\").notna())\n",
    "        & (df.get(\"unit_level\", \"session\") == \"session\")\n",
    "        & df.get(\"rel_path_acc\").notna()\n",
    "    )\n",
    "    idx_sess = df[mask_sess].index.tolist()\n",
    "    if not idx_sess:\n",
    "        print(\"[WARN] No Engagnition session×ACC rows found.\")\n",
    "        return\n",
    "\n",
    "    # --- compute RAW per session row with progress bar ---\n",
    "    raws = pd.Series(index=df.index, dtype=\"float64\")\n",
    "    ok, fail = 0, 0\n",
    "\n",
    "    print(\"[INFO] Computing ACC RAW (median SVM) …\")\n",
    "    for i in tqdm(idx_sess, desc=\"ACC sessions\", unit=\"row\"):\n",
    "        rel = df.at[i, \"rel_path_acc\"]\n",
    "        if not isinstance(rel, str) or not rel:\n",
    "            fail += 1\n",
    "            continue\n",
    "        fcsv = os.path.join(args.data_root, rel)\n",
    "        if not os.path.isfile(fcsv):\n",
    "            fail += 1\n",
    "            continue\n",
    "        try:\n",
    "            acc = read_acc_csv(fcsv)\n",
    "            svm = get_svm_from_frame(acc)\n",
    "            rv = pd.to_numeric(svm, errors=\"coerce\").dropna().median()\n",
    "            if pd.notna(rv):\n",
    "                raws.at[i] = float(rv)\n",
    "                ok += 1\n",
    "            else:\n",
    "                fail += 1\n",
    "        except Exception:\n",
    "            fail += 1\n",
    "\n",
    "    df.loc[raws.index, \"movement_intensity_raw\"] = raws\n",
    "\n",
    "    # --- build groups for z-scaling cascade ---\n",
    "    work = df.loc[idx_sess, [\"participant_id\", \"condition\", \"movement_intensity_raw\"]].copy()\n",
    "    work[\"raw\"] = pd.to_numeric(work[\"movement_intensity_raw\"], errors=\"coerce\")\n",
    "    valid = work[\"raw\"].notna()\n",
    "    if valid.sum() == 0:\n",
    "        print(\"[ERROR] No valid RAW values computed.\")\n",
    "        df.to_csv(args.out, index=False, encoding=\"utf-8-sig\")\n",
    "        return\n",
    "\n",
    "    # Global stats\n",
    "    g_med, g_iqr = robust_center_scale(work.loc[valid, \"raw\"])\n",
    "\n",
    "    # Precompute per (pid, condition) and per condition stats\n",
    "    pc_stats = {}\n",
    "    for (pid, cond), sub in work.groupby([\"participant_id\", \"condition\"]):\n",
    "        med, iqr = robust_center_scale(sub[\"raw\"])\n",
    "        pc_stats[(pid, cond)] = (med, iqr)\n",
    "\n",
    "    c_stats = {}\n",
    "    for cond, sub in work.groupby([\"condition\"]):\n",
    "        med, iqr = robust_center_scale(sub[\"raw\"])\n",
    "        c_stats[cond] = (med, iqr)\n",
    "\n",
    "    # --- compute Z/BIN with cascade ---\n",
    "    z_out = pd.Series(index=df.index, dtype=\"float64\")\n",
    "    bin_out = pd.Series(index=df.index, dtype=\"Int64\")\n",
    "\n",
    "    for i in idx_sess:\n",
    "        r = raws.at[i]\n",
    "        if pd.isna(r):\n",
    "            continue\n",
    "\n",
    "        pid = df.at[i, \"participant_id\"]\n",
    "        cond = df.at[i, \"condition\"]\n",
    "\n",
    "        med, iqr = pc_stats.get((pid, cond), (np.nan, np.nan))\n",
    "        if not (np.isfinite(iqr) and iqr > 0):\n",
    "            med, iqr = c_stats.get(cond, (np.nan, np.nan))\n",
    "        if not (np.isfinite(iqr) and iqr > 0):\n",
    "            med, iqr = g_med, g_iqr\n",
    "        if not (np.isfinite(iqr) and iqr > 0):\n",
    "            # last resort: unscaled deviation from median\n",
    "            z = r - (med if np.isfinite(med) else 0.0)\n",
    "        else:\n",
    "            z = (r - med) / iqr\n",
    "\n",
    "        z_out.at[i] = float(z)\n",
    "        bin_out.at[i] = int(z >= 0.0)\n",
    "\n",
    "    df.loc[z_out.index, \"movement_intensity_z\"] = z_out\n",
    "    df.loc[bin_out.index, \"movement_intensity_bin\"] = bin_out\n",
    "\n",
    "    # --- optional: propagate session z/bin to block rows (same pid+cond, ACC) ---\n",
    "    if args.propagate_blocks:\n",
    "        mask_block = (\n",
    "            (df.get(\"dataset\") == \"Engagnition\")\n",
    "            & ((df.get(\"modality\") == \"ACC\") | df.get(\"rel_path_acc\").notna())\n",
    "            & (df.get(\"unit_level\") == \"block\")\n",
    "        )\n",
    "        blocks = df[mask_block].index.tolist()\n",
    "        if blocks:\n",
    "            # Build lookup: (pid, cond) -> median z/bin of sessions (if many)\n",
    "            sess_tab = df.loc[idx_sess, [\"participant_id\", \"condition\",\n",
    "                                         \"movement_intensity_z\", \"movement_intensity_bin\"]].copy()\n",
    "            sess_tab[\"z\"] = pd.to_numeric(sess_tab[\"movement_intensity_z\"], errors=\"coerce\")\n",
    "            # choose median z per pid+cond; bin via majority (or z>=0 of median)\n",
    "            z_map = sess_tab.groupby([\"participant_id\", \"condition\"])[\"z\"].median()\n",
    "            for j in blocks:\n",
    "                pid = df.at[j, \"participant_id\"]\n",
    "                cond = df.at[j, \"condition\"]\n",
    "                if (pid, cond) in z_map.index:\n",
    "                    z_val = z_map.loc[(pid, cond)]\n",
    "                    df.at[j, \"movement_intensity_z\"] = z_val\n",
    "                    df.at[j, \"movement_intensity_bin\"] = int(float(z_val) >= 0.0)\n",
    "\n",
    "    # --- save and summary ---\n",
    "    df.to_csv(args.out, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"[OK] RAW computed: {ok}, failed: {fail}\")\n",
    "    eng_rows = df.loc[idx_sess]\n",
    "    vc = pd.to_numeric(eng_rows[\"movement_intensity_bin\"], errors=\"coerce\").value_counts(dropna=False)\n",
    "    print(\"[OK] BIN value counts (session×ACC):\")\n",
    "    print(vc.to_string())\n",
    "    print(\"[OK] Z describe (session×ACC):\")\n",
    "    print(pd.to_numeric(eng_rows[\"movement_intensity_z\"], errors=\"coerce\").describe())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be1b2e-ae90-4e3c-81c9-2016e5d81227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
